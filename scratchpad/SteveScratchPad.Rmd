---
title: "Basic_exploratory_steve"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(dplyr)
library(ggplot2)
library(readr)
library(lubridate)
library(caret)
library(tidyr)
library(broom)

#setwd("~/Dropbox/datasciencefinalproject/DonorsChoose/data")

setwd("C:/Users/Steve/Dropbox/datasciencefinalproject/DonorsChoose/data")

projects <- read_csv("opendata_projects_output.csv")

projects <- projects %>% mutate(percent_funded = (total_donations / total_price_including_optional_support))


#test for normalacy of percent funded
hist(projects$percent_funded)
qqnorm(projects$percent_funded)
print("Data is nowhere near normal, looks like logistic analysis of funded vs non-funded make much more sense.")

#poverty level graph
#amount of goal
projects %>% ggplot(aes(x = poverty_level, y = percent_funded)) + geom_boxplot()
#amount of goal jitter plot
projects %>% ggplot(aes(x = poverty_level, y = funding_status)) + geom_jitter(size = .001)

poverty <- projects %>% group_by(poverty_level, funding_status) %>% summarise(total= n()) %>% 
  group_by(poverty_level) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup 


#percent funded
poverty %>% ggplot(aes(poverty_level, percent)) + geom_point(aes(color = funding_status))


#latitude and longitude level graph by amount of goal
projects %>% ggplot(aes(x = school_latitude, y = percent_funded)) + geom_point()
projects %>% ggplot(aes(x = school_longitude, y = percent_funded)) + geom_point()

#state graph
#percent of goal
projects %>% ggplot(aes(x = school_state, y = percent_funded)) + geom_boxplot()
state <- projects %>% group_by(school_state, funding_status) %>% summarise(total= n()) %>% 
  group_by(school_state) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup

state %>% ggplot(aes(school_state, percent)) + geom_point(aes(color = funding_status)) + theme(
    axis.text.x=element_text(angle=90, size=8))

#school urban vs rual
projects %>% ggplot(aes(x = school_metro, y = percent_funded)) + geom_boxplot()

urban <- projects %>% group_by(school_metro, funding_status) %>% summarise(total= n()) %>% 
  group_by(school_metro) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup

urban %>% ggplot(aes(school_metro, percent)) + geom_point(aes(color = funding_status))

#teacher prefix
projects %>% ggplot(aes(x = teacher_prefix, y = percent_funded)) + geom_boxplot()

prefix <- projects %>% group_by(teacher_prefix, funding_status) %>% summarise(total= n()) %>% 
  group_by(teacher_prefix) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup

prefix %>% ggplot(aes(teacher_prefix, percent)) + geom_point(aes(color = funding_status))

#charter school

projects %>% group_by(school_charter, funding_status) %>% summarise(total= n()) %>% 
  group_by(school_charter) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(school_charter, percent)) + geom_point(aes(color = funding_status))

#magnent school

projects %>% group_by(school_magnet, funding_status) %>% summarise(total= n()) %>% 
  group_by(school_magnet) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(school_magnet, percent)) + geom_point(aes(color = funding_status))

#school year round

projects %>% group_by(school_year_round, funding_status) %>% summarise(total= n()) %>% 
  group_by(school_year_round) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(school_year_round, percent)) + geom_point(aes(color = funding_status))

#new Leaders New Schools affiliated 

projects %>% group_by(school_nlns, funding_status) %>% summarise(total= n()) %>% 
  group_by(school_nlns) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(school_nlns, percent)) + geom_point(aes(color = funding_status))

#knowledge is power public charter school (KIPP)

projects %>% group_by(school_kipp, funding_status) %>% summarise(total= n()) %>% 
  group_by(school_kipp) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(school_kipp, percent)) + geom_point(aes(color = funding_status))

#school charter ready promise

projects %>% group_by(school_charter_ready_promise, funding_status) %>% summarise(total= n()) %>% 
  group_by(school_charter_ready_promise) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(school_charter_ready_promise, percent)) + geom_point(aes(color = funding_status))

#teach for america teacher

projects %>% group_by(teacher_teach_for_america, funding_status) %>% summarise(total= n()) %>% 
  group_by(teacher_teach_for_america) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(teacher_teach_for_america, percent)) + geom_point(aes(color = funding_status))

#ny teaching fellow

projects %>% group_by(teacher_ny_teaching_fellow, funding_status) %>% summarise(total= n()) %>% 
  group_by(teacher_ny_teaching_fellow) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(teacher_ny_teaching_fellow, percent)) + geom_point(aes(color = funding_status))


#primary focus subject

projects %>% group_by(primary_focus_subject, funding_status) %>% summarise(total= n()) %>% 
  group_by(primary_focus_subject) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(primary_focus_subject, percent)) + geom_point(aes(color = funding_status)) + theme(
    axis.text.x=element_text(angle=90, size=8))

#primary focus area

projects %>% group_by(primary_focus_area, funding_status) %>% summarise(total= n()) %>% 
  group_by(primary_focus_area) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(primary_focus_area, percent)) + geom_point(aes(color = funding_status)) + theme(
    axis.text.x=element_text(angle=90, size=8))


#resource type

projects %>% group_by(resource_type, funding_status) %>% summarise(total= n()) %>% 
  group_by(resource_type) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(resource_type, percent)) + geom_point(aes(color = funding_status)) + theme(
    axis.text.x=element_text(angle=90, size=8))

#grade level

projects %>% group_by(grade_level, funding_status) %>% summarise(total= n()) %>% 
  group_by(grade_level) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(grade_level, percent)) + geom_point(aes(color = funding_status)) + theme(
    axis.text.x=element_text(angle=90, size=8))

#total price excluding optional support

projects %>% ggplot(aes(x = total_price_excluding_optional_support, y = percent_funded)) + geom_smooth()

#students reached

projects %>% ggplot(aes(x = students_reached, y = percent_funded)) + geom_smooth()

#eligible for double your impact match

projects %>% group_by(eligible_double_your_impact_match, funding_status) %>% summarise(total= n()) %>% 
  group_by(eligible_double_your_impact_match) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(eligible_double_your_impact_match, percent)) + geom_point(aes(color = funding_status)) + theme(
    axis.text.x=element_text(angle=90, size=8))

#eligible for almost home match

projects %>% group_by(eligible_almost_home_match, funding_status) %>% summarise(total= n()) %>% 
  group_by(eligible_almost_home_match) %>% mutate(totals = sum(total), percent = total/totals) %>% ungroup %>% 
  ggplot(aes(eligible_almost_home_match, percent)) + geom_point(aes(color = funding_status)) + theme(
    axis.text.x=element_text(angle=90, size=8))

#date posted

projects %>% ggplot(aes(x = date_posted, y = percent_funded)) + geom_smooth()

projects %>% mutate(sintry = asin(percent_funded)) %>% ggplot(aes(x = date_posted, y = sintry)) + geom_smooth()


```


```{r eval=FALSE}

##MODELING

#This chunk is just trying a numer of things, see next chunk for best model so far

#create column for binary 1=funded, 0 = not funded regression
projects <- projects %>% mutate(funded = ifelse(funding_status == "completed", 1 , 0))

#split into test and train data sets (90% in train)
n_test <- round(nrow(projects) / 10)
test_indices <- sample(1:nrow(projects), n_test, replace=FALSE)
test <- projects[test_indices,]
train <- projects[-test_indices,]


#root mean square error defined in class to use test models, think this will work with logistic output, not 100% sure
RMSE <- function(true_ratings, predicted_ratings){
    sqrt(mean((true_ratings - predicted_ratings)^2))
}

#using confusion matrix to test accurary

tab <- table(  dat$glm_pred , dat$truth )
conf_matrix <- confusionMatrix(tab)
conf_matrix$table
conf_matrix$overall["Accuracy"]

#model based off of date alone

fit <- glm(funded ~ date_posted, data=train, family = "binomial")


#see train documentation for other logistic methods http://topepo.github.io/caret/Logistic_Regression.html
control <- trainControl(method='cv', number=10, p=.8)

logreg <- train(funded ~ total_price_excluding_optional_support,
             data = train,
             method = "logicBag")

mod_fit <- train(funded ~ total_price_excluding_optional_support + primary_focus_area + school_charter + primary_focus_subject + students_reached,  data=train, method="glm", family="binomial")


#fliter out less used variables
projects2 <- projects %>% filter(school_year_round == 'f'& school_magnet == 'f'& school_charter == 'f'& school_nlns == 'f'& school_kipp == 'f'& school_charter_ready_promise == 'f'& teacher_teach_for_america == 'f'& teacher_ny_teaching_fellow == 'f')


#trying most fitting variables
mod_fit2 <- train(funded ~ total_price_excluding_optional_support + primary_focus_area + primary_focus_subject + students_reached + date_posted + teacher_prefix + school_state + school_metro + resource_type + grade_level + eligible_double_your_impact_match + date_posted,  data=projects2, method="glm", family="binomial")

#picking a few mor likely important variables
mod_fit3 <- train(funded ~ total_price_excluding_optional_support + primary_focus_area + primary_focus_subject + date_posted + teacher_prefix + school_state + eligible_double_your_impact_match + date_posted,  data=projects2, method="glm", family="binomial")

#even fewer variables
mod_fit4 <- train(funded ~ total_price_excluding_optional_support + primary_focus_area + primary_focus_subject + students_reached + date_posted,  data=projects2, method="glm", family="binomial")

mod_fit5 <- train(funded ~ total_price_excluding_optional_support + primary_focus_area + date_posted,  data=projects2, method="glm", family="binomial")

mod_fit6 <- train(funded ~ total_price_excluding_optional_support,  data=projects2, method="glm", family="binomial")
```

```{r}
#modeling start

#split into test and train data sets (90% in train), did not use since train() uses cross correlation itself to calculate RMSE, but could be used in future to double check
n_test <- round(nrow(projects) / 10)
test_indices <- sample(1:nrow(projects), n_test, replace=FALSE)
test <- projects[test_indices,]
train <- projects[-test_indices,]

#fliter out projects that had lesser used variables that seemed to have an effect
projects2 <- projects %>% filter(school_year_round == 'f'& school_magnet == 'f'& school_charter == 'f'& school_nlns == 'f'& school_kipp == 'f'& school_charter_ready_promise == 'f'& teacher_teach_for_america == 'f'& teacher_ny_teaching_fellow == 'f')


#simple model to start with, but best predictor so far, can just add variables total price and retrain. view model to see RMSE determined by cross correlation.
model <- train(funded ~ total_price_excluding_optional_support,  data=projects2, method="glm", family="binomial")

```

#### Building a preditction model for proposal success

The first attempt to build a model was to use the glm method in the train function and select several variables from the earlier exploratory analysis that looked to have an effect. These variables included: amount of money asked for, school state, primary focus, primary subject, resource type, date posted. We used glm because our outcome is either funded or not funded and glm works well for logistic regression.

```{r}
#create column for binary 1 = funded, 0 = not funded regression
projects <- projects %>% mutate(funded = ifelse(funding_status == "completed", 1 , 0))

fit_selected_components <- train(funded ~ total_price_excluding_optional_support + primary_focus_area + school_charter + primary_focus_subject + students_reached + school_state + resource_type + date_posted,  data=projects, method="glm", family="binomial")

fit_selected_components

```

The RMSE from this method is not great, but it is a start so we tried to improve on it. First we filtered out some of the uncommon variables, that appeared to have an effect in the exploratory analysis. For example if the teacher was in teacher in teach for America, a New York teach fellow, was it a charter school, or other school types. All total these only filtered out few percent of the applications, and are factors the requesters can't change so they are not useful in building a prediction model. We then ran the training again.

```{r}

#fliter out less used variables
projects2 <- projects %>% filter(school_year_round == 'f'& school_magnet == 'f'& school_charter == 'f'& school_nlns == 'f'& school_kipp == 'f'& school_charter_ready_promise == 'f'& teacher_teach_for_america == 'f'& teacher_ny_teaching_fellow == 'f')

#run train again
fit_selected_components_filtered <- train(funded ~ total_price_excluding_optional_support + primary_focus_area + primary_focus_subject + students_reached + school_state + resource_type + date_posted,  data=projects2, method="glm", family="binomial")

fit_selected_components_filtered

```

Removing these proposals did show an effect in an improvement of RMSE, even though it is . The next approach was that perhaps our model was trying to fit to many parameters, so we pared it down to only include the factors that the exploratory analysis showed to have the greatest effect. These factors were: cost, date of posting, and resource type.

```{r}
#run train again using most selective variables
fit_more_selective_components <- train(funded ~ total_price_excluding_optional_support +  date_posted + resource_type,  data=projects2, method="glm", family="binomial")

fit_more_selective_components

```

This shows an even greater improvement in RMSE. In looking back at the data it was clear that the cost requested has the strongest effect. So we decided to run train again to see if that variable alone might improve our accurary (as shown by RMSE).


```{r}
fit_cost_only <- train(funded ~ total_price_excluding_optional_support,  data=projects2, method="glm", family="binomial")

fit_cost_only

```

So using all the data, except the contents of the essay, provided by the requesters it appears that the best model we can build is using the total cost as a predictor.



This shows a further, though small improvement of RMSE. So it appears to not be worth adding in the other factors. As shown in the exploratory analysis the vast majority of proposals request less than $1500, and above this amount cost requested become less predicitve. So for one last attempt using this data we looked to see if filtering out proposals above $1500 would improve the model.

```{r}
projects3 <- projects2 %>% filter(total_price_excluding_optional_support < 1500)

fit_cost_only_filtered <- train(funded ~ total_price_excluding_optional_support,  data=projects3, method="glm", family="binomial")

fit_cost_only_filtered

```


