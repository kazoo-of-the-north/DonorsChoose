---
title: "FinalProjectScratchpad"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readr)
library(dplyr)
library(ggplot2)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r report start time} 
startTime<-timestamp()
startTime
```

```{r load csv files}

# Hazel's method: 
# Read in the projects info
#filename <- "/Users/sov436/courses/E-107/DonorsChoose/opendata_projects.zip"
#setwd("/Users/jimschlough/Documents/Harvard/CSC-E107/Final project/DonorsChoose/data/" )
projectsFilename <- "/Users/jimschlough/Documents/Harvard/CSC-E107/Final project/DonorsChoose/data/opendata_projects_output.csv"
#projects <- read_csv(unz(filename, "opendata_projects.csv")) 
if (!exists("projects")) { 
  if (!file.exists(projectsFilename))
  { 
    sprintf("File not found: %s", projectsFilename); 
    stop();
  }
  projects <- read_csv(projectsFilename);  
  }
projects <- projects %>% filter(date_posted > '2013-12-31' & date_posted < '2015-01-01')

# populate donations
donationsFilename<-"/Users/jimschlough/Documents/Harvard/CSC-E107/Final project/DonorsChoose/data/opendata_donations.csv"
if (!exists("donations")) {donations <- read_csv(donationsFilename) }
# number of donations prior to filtering out only those with 2014 project IDs (should be ~4623094)
count(donations)$n
donations<- donations %>% filter(`_projectid` %in% projects$`_projectid`) 
# number of donations after filtering out only those with 2014 project IDs (should be ~1076489)
count(donations)$n

# OPTIONAL test out that writing & decompressing and reading RDS file works 
test_rds<-FALSE
if(test_rds) { 
  write_rds(donations, "./opendata_2014_donations.rds.gz", compress = "gz") ;
  donations<-read_rds( "./opendata_2014_donations.rds.gz") ;
  # number of donations after writing & decompressing and reading RDS file 
  count(donations)$n
}


# fill resources .... still having problems here
resourcesFilename <- "/Users/jimschlough/Documents/Harvard/CSC-E107/Final\ project/DonorsChoose/data/opendata_resources.csv"

numberOfRowsToRead<-1000
numberOfRowsToSkip<-0
resources <- read_csv(resourcesFilename) #, n_max = numberOfRowsToRead )

resources<- resources %>% filter(`_projectid` %in% projects$`_projectid`)
```

```{r breaking resources out into RDS files, eval=FALSE, echo=FALSE}

# breaking resources out into RDS files:
write_rds(resources, "./opendata_2014_resources.rds.gz", compress = "gz")

# write out 2 segments for 2014 resources 
numberOfResources<-count(resources)$n
numberOfResources
resources1of2<-head(resources, round(numberOfResources/2))
count(resources1of2)$n

resources2of2<-anti_join(resources, resources1of2)
count(resources2of2)$n
write_rds(resources1of2, "./opendata_2014_resources1of2.rds.gz", compress = "gz")
write_rds(resources2of2, "./opendata_2014_resources2of2.rds.gz", compress = "gz")
rm(resources1of2)
rm(resources2of2)
# how to read it back in later: 
#donations<-read_rds( "./opendata_2014_resources.rds.gz") 

```


Loading Essays
```{r loading essays}

# fill essays 
essaysFilename <- "/Users/jimschlough/Documents/Harvard/CSC-E107/Final project/DonorsChoose/data/opendata_essays.csv"

if (!exists("essays")) { 
  if (!file.exists(essaysFilename))
  { 
    sprintf("File not found: %s", essaysFilename); 
    stop();
  }
  essays <- read_csv(essaysFilename);  
} 

essays <- essays %>% filter( `_projectid` %in% projects$`_projectid`)
```

Writing out Essays RDS file
```{r Writing out Essays RDS file, eval=FALSE, echo=FALSE}
# this RDS file ends up being ~193Mb, which is too large to put into our git repository
write_rds(essays, "./opendata_2014_essays.rds.gz", compress = "gz")


```


## Basic data agreement
Here, we have a look at the total number of projects that were recorded for 2014, as well as the number of essays that appear in the data. This is a sanity check to see how many projects we have that possibly might not have an essay.
```{r data agreement and total number of projects and essays }
# number of projects matches number of essays
numberOfProjects<-count(projects)$n
numberOfEssays<-count(essays)$n
if (  numberOfProjects == numberOfEssays)
{ 
  print("Number of projects matches number of essays");
};
else 
{
  print("Number of projects DOES NOT match number of essays, where: ");
  # specifics of the difference
  sprintf("The number of projects is: %d while the number of essays is: %d", numberOfProjects, numberOfEssays);
  # number of projects without an essay:
  sprintf("So we have %d more projects than essays", numberOfProjects - numberOfEssays)
};

```
##Looking at Funding Status
In the *projects* dataset, we have the *funding_status* variable. The *funding_status* will have one of 3 distinct outcomes: *completed, expired,* or *reallocated*. In order for a project to become funded, it must meet its funding goal within its timeframe or expire. If the project expires and has pledged funds that will no longer be disbursed, these funds will either be returned to the donor, or at the option of the donor they may be reallocated to a different project. This is our interpretation of the policy as stated [here](http://help.donorschoose.org/hc/en-us/articles/201937866-Transferring-donations-from-one-project-to-another).


```{r funding status}

# number of distinct outcomes projects had 
outcome_types<-as.factor(unique(projects$funding_status))
outcome_types

# overall project completed / expired / reallocated
ggplot(projects, aes(funding_status)) +
  geom_bar(aes(color=funding_status, fill=funding_status))

```

# Breakout data into dataset 1-5
This is where we broke out the data into small enough piece to get it checked in, 
to make it accessible to anyone trying to run our project. Once we have this data uploaded, we'll
decide how to integrate it into the final project.

##Breakout dataset 1 
```{r  break out set 1, eval = FALSE, echo = FALSE }
# my first try at making smaller segments
numberOfEssays<-count(essays)$n
numberOfEssays
roughlyOneFifthOfEssays<-round(numberOfEssays/5)

# break out set 1 
essays1of5<-head(essays,roughlyOneFifthOfEssays)
write_rds(essays1of5, "./opendata_2014_essays1of5.rds.gz", compress = "gz")
# total number of essays in essays before any are removed  
count(essays )$n
# number of essays in essays1of5
essays1of5_count<- count(essays1of5)$n
essays1of5_count

# assumption here is that _projectid and _teacherid together uniquely identify an essay
# remove the ones put into the first record set
essays<-anti_join(essays, essays1of5, by=c("_projectid","_teacherid"))

# total number of essays in essays after 1st 5 are removed  
count(essays )$n

# optionally remove essays1of5, after we know all the records will make it 
rm(essays1of5)


```

##Breakout dataset 2 
```{r break out set 2, eval = FALSE, echo = FALSE }
# break out set 2 
essays2of5<-head(essays,roughlyOneFifthOfEssays)
write_rds(essays2of5, "./opendata_2014_essays2of5.rds.gz", compress = "gz")

# total number of essays in essays before 2nd batch are removed  
count(essays )$n
# number of essays in essays2of5
essays2of5_count<- count(essays2of5)$n
essays2of5_count

# assumption here is that _projectid and _teacherid together uniquely identify an essay
# remove the ones put into the first record set 
essays<-anti_join(essays, essays2of5, by=c("_projectid","_teacherid"))

# total number of essays in essays after 2nd batch are removed  
count(essays )$n

# optionally remove essays2of5, after we know all the records will make it 
rm(essays2of5)

```

##Breakout dataset 3  
```{r break out set 3,  eval = FALSE, echo = FALSE }
# break out set 3 
essays3of5<-head(essays,roughlyOneFifthOfEssays)
write_rds(essays3of5, "./opendata_2014_essays3of5.rds.gz", compress = "gz")

# total number of essays in essays before 3rd batch are removed  
count(essays )$n
# number of essays in essays3of5
essays3of5_count<- count(essays3of5)$n
essays3of5_count

# assumption here is that _projectid and _teacherid together uniquely identify an essay
# remove the ones put into the first record set 
essays<-anti_join(essays, essays3of5, by=c("_projectid","_teacherid"))

# total number of essays in essays after 3rd batch are removed  
count(essays )$n

# optionally remove essays3of5, after we know all the records will make it 
rm(essays3of5)


```

##Breakout dataset 4 
```{r break out set 4, eval = FALSE, echo = FALSE}

# break out set 4 
essays4of5<-head(essays,roughlyOneFifthOfEssays)
write_rds(essays4of5, "./opendata_2014_essays4of5.rds.gz", compress = "gz")

# total number of essays in essays before 4th batch are removed  
count(essays )$n
# number of essays in essays4of5
essays4of5_count<- count(essays4of5)$n
essays4of5_count

# assumption here is that _projectid and _teacherid together uniquely identify an essay
# remove the ones put into the first record set 
essays<-anti_join(essays, essays4of5, by=c("_projectid","_teacherid"))

# total number of essays in essays after 4th batch are removed  
count(essays )$n

# optionally remove essays4of5, after we know all the records will make it 
rm(essays4of5)
```

##Breakout dataset 5
```{r break out set 5, eval = FALSE, echo = FALSE}
# break out set 5 is what remains 
essays5of5<- essays 

write_rds(essays5of5, "./opendata_2014_essays5of5.rds.gz", compress = "gz")

# total number of essays in essays before 5th batch are removed  
count(essays )$n
# number of essays in essays5of5
essays5of5_count<- count(essays5of5)$n
essays5of5_count

# total number of essays in essays after 5th batch are removed  
count(essays5of5 )$n

# optionally remove essays5of5, after we know all the records will make it 
rm(essays5of5)


```

```{r REASSEMBLY TEST, eval = FALSE, echo = FALSE }
#####
#
#  REASSEMBLY TEST
# put it all back together again to see in the number of records agrees with what we began having

rm(essays)
# rm(essays1of5)
# rm(essays2of5)
# rm(essays3of5)
# rm(essays4of5)
# rm(essays5of5)

essays1of5<-read_rds("./opendata_2014_essays1of5.rds.gz")
essays2of5<-read_rds("./opendata_2014_essays2of5.rds.gz")
essays3of5<-read_rds("./opendata_2014_essays3of5.rds.gz")
essays4of5<-read_rds("./opendata_2014_essays4of5.rds.gz")
essays5of5<-read_rds("./opendata_2014_essays5of5.rds.gz")

essays<-essays1of5
essays<-rbind(essays,essays2of5)
essays<-rbind(essays,essays3of5)
essays<-rbind(essays,essays4of5)
essays<-rbind(essays,essays5of5)
# total number of records test, test passes if true
# total number of reassembled essays:
count(essays)$n

# original number of essays
numberOfEssays

# ultimate reassembly test passes if true
numberOfEssays==count(essays)$n

```


```{r report stop time} 
stopTime<-timestamp()
stopTime
```

